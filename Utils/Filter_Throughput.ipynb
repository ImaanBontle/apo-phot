{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041040d-3945-45b5-a057-185a0eb4292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing environment...\")\n",
    "\n",
    "import platform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from astropy import table as tbl\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from scipy import constants as c\n",
    "from scipy import interpolate\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15e82a-4c21-4acf-a9d1-84a20a4516de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### All functions\n",
    "\n",
    "\n",
    "# Function to parse tables and set any rows with NaNs to zero, to avoid errors\n",
    "def RemoveNaNs(tableObj):\n",
    "    for col in tableObj.colnames:\n",
    "        for x in range(0, len(tableObj[col]), 1):\n",
    "            if np.isnan(tableObj[col][x]):\n",
    "                tableObj[col][x] = 0\n",
    "    return tableObj\n",
    "\n",
    "\n",
    "# Function to use appropriate OS directory structure\n",
    "def GetDirStruct():\n",
    "    match platform.system():\n",
    "        case \"Windows\":\n",
    "            dirPrefix = \"D:/\"\n",
    "        case \"Linux\" | \"Ubuntu\":\n",
    "            dirPrefix = \"/mnt/d/\"\n",
    "        case \"macOS\" | \"Darwin\":\n",
    "            dirPrefix = \"/Volumes/Storage/\"\n",
    "        case _:\n",
    "            raise Exception(f\"OS not recognised: \\\"{platform.system()}\\\". Please define a custom switch inside GetDirStruct().\")\n",
    "    return dirPrefix\n",
    "\n",
    "\n",
    "# Function to grab list of spectra in a directory\n",
    "def GetSpec():\n",
    "    dirPrefix = GetDirStruct()\n",
    "    specDir = dirPrefix + specFolder\n",
    "    specList = !bash -c \"ls {specDir}*1D.fits\"\n",
    "    specList = [file.split('/')[-1] for file in specList]\n",
    "    specNames = [file.split('_')[0] for file in specList]\n",
    "    return specDir, specList, specNames\n",
    "\n",
    "\n",
    "# Function to import files to dictionary\n",
    "def ImportSpec(specDir, specList, specNames):\n",
    "    specData = {}\n",
    "    for file, name in tqdm(list(zip(specList, specNames)), desc=\"Importing spectra\"):\n",
    "        specRaw = fits.open(specDir + file)\n",
    "        specFlux = specRaw[1].data * u.Jy\n",
    "        specWave = specRaw[9].data * u.m\n",
    "        specData[name] = tbl.QTable([specWave, specFlux], names=(\"Wavelength\", \"Flux\"))\n",
    "        specData[name] = RemoveNaNs(specData[name])\n",
    "        specRaw.close()\n",
    "    return specData\n",
    "\n",
    "\n",
    "# Function to plot the spectra\n",
    "def PlotSpec(specData, specList, specNames):\n",
    "    !bash -c \"mkdir -p ../../Working_Directory/Apo_Phot_Utils/{outputFolder}plots\"\n",
    "    for file, name in tqdm(zip(specList, specNames), desc=\"Plotting galaxies\", total=len(specList)):\n",
    "        plt.plot(specData[name][\"Wavelength\"], specData[name][\"Flux\"])\n",
    "        plt.xscale('log')\n",
    "        plt.savefig(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}plots/{name}.png\")\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "# Function to grab list of filter curves\n",
    "def GetFilter():\n",
    "    dirPrefix = GetDirStruct()\n",
    "    filterDir = dirPrefix + filterFolder\n",
    "    filterList = !bash -c \"ls {filterDir}\"\n",
    "    filterList = [file.split('/')[-1] for file in filterList]\n",
    "    filterNames = [file.split('_')[0] for file in filterList]\n",
    "    return filterDir, filterList, filterNames\n",
    "\n",
    "# Function to import filters to a dictionary\n",
    "def ImportFilter(filterDir, filterList, filterNames):\n",
    "    filterData = {}\n",
    "    for file, name in tqdm(zip(filterList, filterNames), desc=\"Importing filters\", total=len(filterList)):\n",
    "        filterData[name] = tbl.QTable.read(filterDir + file, format=\"ascii\")\n",
    "        filterData[name][\"Microns\"].unit = u.um\n",
    "        filterData[name].rename_column(\"Microns\", \"Wavelength\")\n",
    "        filterData[name][\"Throughput\"].unit = u.dimensionless_unscaled\n",
    "        filterData[name] = RemoveNaNs(filterData[name])\n",
    "    return filterData\n",
    "\n",
    "# Function to interpolate datapoints\n",
    "def InterpFunc(funcXs, funcYs):\n",
    "    funcCubic = interpolate.interp1d(funcXs, funcYs, kind='cubic')\n",
    "    return funcCubic\n",
    "\n",
    "# Function to find grid overlap for convolutions of target using input\n",
    "def FindGrid(targetGrid, inputGrid, inputData):\n",
    "    # Sort all arrays\n",
    "    idxSorted = np.argsort(inputGrid)\n",
    "    sortedGrid = inputGrid[idxSorted]\n",
    "    sortedTarget = np.sort(targetGrid)\n",
    "    # Find first value in input that overlaps with target\n",
    "    if sortedGrid[0] < sortedTarget[0]:\n",
    "        idxLeft = np.searchsorted(sortedGrid, sortedTarget[0], side=\"right\")\n",
    "        if inputGrid[idxLeft-1] == sortedTarget[0]:\n",
    "            idxLeft -= 1\n",
    "    else:\n",
    "        idxLeft = 0\n",
    "    # Find last value in input that overlaps with target\n",
    "    if sortedGrid[-1] > sortedTarget[-1]:   \n",
    "        idxRight = np.searchsorted(sortedGrid, sortedTarget[-1], side=\"left\")\n",
    "        if inputGrid[idxRight] != sortedTarget[-1]:\n",
    "            idxRight -= 1\n",
    "    else:\n",
    "        idxRight = -1\n",
    "    # Return the section of input that overlaps target\n",
    "    overlapGrid = sortedGrid[idxLeft:idxRight]\n",
    "    overlapData = inputData[idxSorted][idxLeft:idxRight]\n",
    "    return overlapGrid, overlapData\n",
    "\n",
    "# Function to manage convolution calculation from first array onto second array\n",
    "def ConvolveFunc(firstXs, firstYs, secondXs, secondYs):\n",
    "    # Interpolate datapoints of first array\n",
    "    firstInterp = InterpFunc(firstXs.to(u.m), firstYs)\n",
    "    # Find relevant convolution grid for first array based on second array\n",
    "    secondOverlapGrid, secondOverlapData = FindGrid(firstXs, secondXs, secondYs)\n",
    "    # Convolve first array onto second array's grid\n",
    "    firstConvolved = firstInterp(secondOverlapGrid.to(u.m))\n",
    "    return firstConvolved, secondOverlapGrid, secondOverlapData\n",
    "\n",
    "# Function to convolve spectra and filters onto same grid\n",
    "def MergeGrids(specFile, filterFile):\n",
    "    specWave = specFile[\"Wavelength\"]\n",
    "    specFlux = specFile[\"Flux\"]\n",
    "    filterWave = filterFile[\"Wavelength\"]\n",
    "    filterThrough = filterFile[\"Throughput\"]\n",
    "    # Find mutual overlaps\n",
    "    specConvolved, filterOverlapGrid, filterOverlapData = ConvolveFunc(specWave, specFlux, filterWave, filterThrough)\n",
    "    filterConvolved, specOverlapGrid, specOverlapData = ConvolveFunc(filterWave, filterThrough, specWave, specFlux)\n",
    "    # Save as tables\n",
    "    specTable = tbl.Table([np.append(specOverlapGrid, filterOverlapGrid).to(u.m), np.append(specOverlapData, specConvolved*u.Jy)], names=(\"Wavelength\", \"Flux\"))\n",
    "    specTable.sort(\"Wavelength\")\n",
    "    filterTable = tbl.Table([np.append(filterOverlapGrid, specOverlapGrid).to(u.m), np.append(filterOverlapData, filterConvolved)], names=(\"Wavelength\", \"Throughput\"))\n",
    "    filterTable.sort(\"Wavelength\")\n",
    "    # Join tables\n",
    "    mergedTable = tbl.join(specTable, filterTable, keys=\"Wavelength\")\n",
    "    return mergedTable\n",
    "\n",
    "# Function to shift flux to photon space\n",
    "def ShiftPhotonSpace(mergedTable):\n",
    "    mergedTable[\"Flux\"] *= mergedTable[\"Wavelength\"]\n",
    "    mergedTable[\"Flux\"].unit *= mergedTable[\"Wavelength\"].unit\n",
    "    return mergedTable\n",
    "\n",
    "# Function to integrate two functions on the same grid\n",
    "def IntegFunc(firstYs, secondYs, commonGrid):\n",
    "    funcIntegrated = np.trapz(firstYs * secondYs, x=commonGrid) * (firstYs.unit * secondYs.unit * commonGrid.unit)\n",
    "    return funcIntegrated\n",
    "\n",
    "# Function to calculate throughput on a merged grid\n",
    "def CalcThroughput(mergedTable):\n",
    "    mergedWave = mergedTable[\"Wavelength\"]\n",
    "    mergedFlux = mergedTable[\"Flux\"]\n",
    "    mergedThrough = mergedTable[\"Throughput\"]\n",
    "    mergedOut = IntegFunc(mergedFlux, mergedThrough, mergedWave)\n",
    "    return mergedOut\n",
    "\n",
    "# Function to find throughput given a spectrum and filter\n",
    "def FindThroughput(specFile, filterFile):\n",
    "    # Convolve onto the same grid\n",
    "    mergedTable = MergeGrids(specFile, filterFile)\n",
    "    # Shift to photon space\n",
    "    mergedTable = ShiftPhotonSpace(mergedTable)\n",
    "    # Integrate through the filter\n",
    "    return CalcThroughput(mergedTable), mergedTable\n",
    "\n",
    "# Function to normalise the throughput to the correct zero-point\n",
    "def NormaliseValue(specTable, specValue):\n",
    "    specThrough = specTable[\"Throughput\"]\n",
    "    specGrid = specTable[\"Wavelength\"]\n",
    "    # norm_ref = 10**(48.6/(-2.5)) # reference zero magnitude\n",
    "    normRef = 1 * u.Jy.to(u.W / ((u.m)**2 * u.Hz)) #* 10**(-9) # reference flat-value in f_nu\n",
    "    normYs = normRef * c.c / specGrid**2 * specGrid # not squared, f_lambda in photon_space\n",
    "    normValue = IntegFunc(specThrough, normYs, specGrid)\n",
    "    specNormed = (specValue / normValue).to(u.nJy)\n",
    "    return specNormed\n",
    "\n",
    "def BalmerBreak(specFile, specName, redshiftFile):\n",
    "    # Define regions\n",
    "    balmerLeftRange = np.array([3500, 3650]) * u.angstrom\n",
    "    balmerRightRange = np.array([3800, 3950]) * u.angstrom\n",
    "    # Grab relevant grids\n",
    "    for row in range(0, len(redshiftFile), 1):\n",
    "        if int(specName) == int(redshiftFile[row][redshiftID]) and redshiftFile[row][redshiftZ] > 0:\n",
    "            redshiftFactor = 1 + redshiftFile[row][redshiftZ]\n",
    "            break\n",
    "        else:\n",
    "            redshiftFactor = np.nan\n",
    "    if redshiftFactor != 0:\n",
    "        balmerLeftWave, balmerLeftSpec = FindGrid(balmerLeftRange, specFile[\"Wavelength\"]/redshiftFactor, specFile[\"Flux\"]*redshiftFactor)\n",
    "        balmerLeftTable = tbl.Table([balmerLeftWave, balmerLeftSpec], names=(\"Wavelength\", \"Flux\"))\n",
    "        balmerRightWave, balmerRightSpec = FindGrid(balmerRightRange, specFile[\"Wavelength\"]/redshiftFactor, specFile[\"Flux\"]*redshiftFactor)\n",
    "        balmerRightTable = tbl.Table([balmerRightWave, balmerRightSpec], names=(\"Wavelength\", \"Flux\"))\n",
    "        # Shift to photon space\n",
    "        balmerLeftTable = ShiftPhotonSpace(balmerLeftTable)\n",
    "        balmerRightTable = ShiftPhotonSpace(balmerRightTable)\n",
    "        # Calculate average flux\n",
    "        balmerLeftVal = np.sum(balmerLeftTable[\"Flux\"]) / len(balmerLeftTable[\"Flux\"]) * balmerLeftTable[\"Flux\"].unit\n",
    "        balmerRightVal = np.sum(balmerRightTable[\"Flux\"]) / len(balmerRightTable[\"Flux\"]) * balmerRightTable[\"Flux\"].unit\n",
    "        # Calculate ratio\n",
    "        balmerRatio = balmerRightVal/balmerLeftVal\n",
    "        balmerVals = [balmerLeftVal, balmerRightVal, balmerRatio]\n",
    "    return balmerVals\n",
    "\n",
    "# Function to loop through filters and balmer breaks for one spectrum\n",
    "def HandleSpectrum(specFile, specName, filterData, redshiftFile):\n",
    "    specValues = []\n",
    "    for filterFile in filterData.values():\n",
    "        specValue, specTable = FindThroughput(specFile, filterFile)\n",
    "        specValues += [NormaliseValue(specTable, specValue), np.nan]\n",
    "    specValues += BalmerBreak(specFile, specName, redshiftFile)\n",
    "    return specValues\n",
    "\n",
    "# Function to loop through each spectrum and save values to a table\n",
    "def LoopSpectra(specData, filterData, redshiftFile):\n",
    "    !bash -c \"mkdir -p ../../Working_Directory/Apo_Phot_Utils/{outputFolder}\"\n",
    "    rows = []\n",
    "    for specName, specFull in tqdm(zip(specData.keys(), specData.values()), desc=\"Galaxies\", total=len(specData.keys())):\n",
    "        rows += [[int(specName)] + HandleSpectrum(specFull, specName, filterData, redshiftFile)]\n",
    "    names = [\"ID\"] + list(chain.from_iterable([[key + \" Through\", key + \" through Error\"] for key in filterData.keys()])) + [\"Balmer_left\", \"Balmer_right\", \"Balmer_ratio\"]\n",
    "    outTable = tbl.Table(rows=rows, names=names)\n",
    "    outTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}throughputs.fits\", overwrite=True)\n",
    "    return outTable\n",
    "\n",
    "# Function to grab photometry files\n",
    "def ImportPhot(photDir):\n",
    "    photTable = tbl.QTable.read(f\"{photDir}/summary.fits\")\n",
    "    return photTable\n",
    "\n",
    "# Function to grab list of slitloss corrections\n",
    "def GrabSlitloss():\n",
    "    lossDir = GetDirStruct() + lossFolder\n",
    "    lossList = {}\n",
    "    for lossPoint in tqdm(lossPoints, desc=\"Grabbing pointings\"):\n",
    "        lossList[lossPoint] = {}\n",
    "        for lossExp in tqdm(lossExps, desc=\"Grabbing exposures\", leave=False):\n",
    "            lossNames = !bash -c \"ls {lossDir}/{lossPoint}/{lossPrefix01}{lossPoint}_{lossExp}{lossPrefix02}*{lossSuffix}\"\n",
    "            # lossList = !bash -c \"ls {lossDir}/{lossPrefix}*{lossSuffix}\"\n",
    "            lossNames = [f\"{file.split('/')[-2]}/{file.split('/')[-1]}\" for file in lossNames]\n",
    "            lossIDs = [file.split('_')[-3] for file in lossNames]\n",
    "            lossIDs = [file[5:11] for file in lossIDs]\n",
    "            lossIDs = [int(file) for file in lossIDs]\n",
    "            lossList[lossPoint][lossExp] = tbl.Table([lossIDs, lossNames], names=(\"ID\", \"Name\"))\n",
    "    return lossDir, lossList\n",
    "\n",
    "# Function to import slitloss corrections\n",
    "def ImportSlitloss(lossDir, lossList, photTable):\n",
    "    lossData = {}\n",
    "    IDList = tbl.Table([photTable[\"ID\"]])\n",
    "    for lossPoint in tqdm(lossList.keys(), desc=\"Matching pointings\"):\n",
    "        lossData[lossPoint] = {}\n",
    "        for lossExp in tqdm(lossList[lossPoint].keys(), desc=\"Matching exposures\", leave=False):\n",
    "            lossData[lossPoint][lossExp] = {}\n",
    "            lossData[lossPoint][lossExp][\"Index\"] = tbl.join(lossList[lossPoint][lossExp], IDList, keys=\"ID\")\n",
    "            for row in tqdm(range(0, len(lossData[lossPoint][lossExp][\"Index\"]), 1), desc=\"Galaxies\", leave=False):\n",
    "                galID = lossData[lossPoint][lossExp][\"Index\"][row][\"ID\"]\n",
    "                galName = lossData[lossPoint][lossExp][\"Index\"][row][\"Name\"]\n",
    "                lossData[lossPoint][lossExp][galID] = tbl.QTable.read(lossDir + galName, format=\"ascii\")\n",
    "                lossData[lossPoint][lossExp][galID].rename_column(\"col1\", \"Slitloss\")\n",
    "                lossData[lossPoint][lossExp][galID].rename_column(\"col2\", \"Wavelength\")\n",
    "                lossData[lossPoint][lossExp][galID][\"Slitloss\"].unit = u.dimensionless_unscaled\n",
    "                lossData[lossPoint][lossExp][galID][\"Wavelength\"].unit = u.um\n",
    "            del lossData[lossPoint][lossExp][\"Index\"]\n",
    "    return lossData\n",
    "\n",
    "# Function to calculate photometry ratios\n",
    "def CalcSlitRatio(photTable, specTable):\n",
    "    combTable = tbl.join(photTable, specTable, keys=\"ID\")\n",
    "    firstFlux = 1\n",
    "    firstThrough = len(photTable.colnames)\n",
    "    fluxCols = combTable.colnames[firstFlux:firstThrough:2]\n",
    "    throughCols = combTable.colnames[firstThrough::2]\n",
    "    ratioTable = tbl.QTable([combTable[\"ID\"]])\n",
    "    fluxNames = []\n",
    "    for col in combTable.colnames[1:]:\n",
    "        combTable[col] = np.where(combTable[col] > 0, combTable[col], np.nan)\n",
    "    for fluxCol in fluxCols:\n",
    "        fluxName = fluxCol.split()[0]\n",
    "        for throughCol in throughCols:\n",
    "            throughName = throughCol.split()[0]\n",
    "            if fluxName == throughName:\n",
    "                ratioTable.add_columns([combTable[fluxCol], combTable[throughCol], combTable[fluxCol]/combTable[throughCol], np.nan], names=(fluxCol, throughCol, f\"{fluxName} Ratio\", f\"{fluxName} Ratio Error\"))\n",
    "                fluxNames += [fluxName]\n",
    "    ratioTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}ratios.fits\", overwrite=True)\n",
    "    return ratioTable, fluxNames\n",
    "\n",
    "# Function to calculate slit-losses at centre of filters\n",
    "def CalcLossTable(lossData, fluxNames):\n",
    "    lossTables = {}\n",
    "    for point in lossData.keys():\n",
    "        lossTables[point] = {}\n",
    "        for exposure in lossData[point].keys():\n",
    "            rows = []\n",
    "            for galaxy in lossData[point][exposure].keys():\n",
    "                row = []\n",
    "                row += [galaxy]\n",
    "                lossInterpolated = interpolate.interp1d(lossData[point][exposure][galaxy][\"Wavelength\"], lossData[point][exposure][galaxy][\"Slitloss\"])\n",
    "                for fluxName in fluxNames:\n",
    "                    centralWave = float(fluxName[1] + '.' + fluxName[2:4]) * u.um\n",
    "                    centralLoss = lossInterpolated(centralWave)\n",
    "                    row += [1/centralLoss * u.dimensionless_unscaled]\n",
    "                rows += [row]\n",
    "            names = [\"ID\"] + [f\"{fluxName} slitloss\" for fluxName in fluxNames]\n",
    "            lossTables[point][exposure] = tbl.QTable(rows=rows, names=names)\n",
    "    return lossTables\n",
    "\n",
    "# Function to calculate slit-loss factor between photometry and model\n",
    "def CalcDiffTable(ratioTable, lossTables):\n",
    "    diffTable = tbl.QTable([ratioTable[\"ID\"]])\n",
    "    # for col in ratioTable.colnames[3::4]:\n",
    "    #     ratioTable[col] = np.where(ratioTable[col] >= 0.02, ratioTable[col], np.nan)\n",
    "    for point in lossTables.keys():\n",
    "        for exposure in lossTables[point].keys():\n",
    "            matchedTable = tbl.join(ratioTable, lossTables[point][exposure], keys=\"ID\")\n",
    "            firstRatio = 3\n",
    "            firstLoss = len(ratioTable.colnames)\n",
    "            ratioNames = matchedTable.colnames[firstRatio:firstLoss:4]\n",
    "            lossNames = matchedTable.colnames[firstLoss:]\n",
    "            tempTable = tbl.QTable([matchedTable[\"ID\"]])\n",
    "            for ratioName in ratioNames:\n",
    "                for lossName in lossNames:\n",
    "                    if ratioName.split()[0] == lossName.split()[0]:\n",
    "                        tempTable.add_column(matchedTable[ratioName]/matchedTable[lossName], name=f\"{ratioName.split()[0]}_{point}_{exposure}\")\n",
    "            diffTable = tbl.join(diffTable, tempTable, keys=\"ID\", join_type='outer')\n",
    "    return diffTable\n",
    "\n",
    "# Function to append average differences across pointings and exposures\n",
    "def CalcAverageDiff(diffTable):\n",
    "    colNames = diffTable.colnames[1:]\n",
    "    k = len(colNames)\n",
    "    for i, colName_i in enumerate(colNames):\n",
    "        stepSize = 0\n",
    "        jumpSize = 0\n",
    "        for j, colName_j in enumerate(colNames[i+1:]):\n",
    "            if colName_i.split('_')[0:2] == colName_j.split('_')[0:2]:\n",
    "                stepSize = j + 1\n",
    "                break\n",
    "        for j, colName_j in enumerate(colNames[i+stepSize::stepSize]):\n",
    "            if colName_i.split('_')[0] == colName_j.split('_')[0] and colName_i.split('_')[1] != colName_j.split('_')[1]:\n",
    "                jumpSize = (j + 1) * stepSize\n",
    "                break\n",
    "        if 0 not in [stepSize, jumpSize]:\n",
    "            k = 0\n",
    "            break\n",
    "    while k < len(colNames):\n",
    "        for i, colName_i in enumerate(colNames[k:k+stepSize:1]):\n",
    "            tempCol = diffTable[colName_i].copy().filled(0)\n",
    "            count = np.where(tempCol > 0, 1, 0)\n",
    "            for j, colName_j in enumerate(colNames[k+i+stepSize:k+i+jumpSize:stepSize]):\n",
    "                tempCol += diffTable[colName_j].filled(0)\n",
    "                count += np.where(diffTable[colName_j].filled(0) > 0, 1, 0)\n",
    "            count = np.where(count > 0, count, np.nan)\n",
    "            diffTable.add_column(tempCol/count, name=f\"{colName_i.split('_')[0]}_{colName_i.split('_')[1]}\")\n",
    "        k += jumpSize\n",
    "    for i, colName_i in enumerate(colNames[0:stepSize]):\n",
    "        tempCol = diffTable[colName_i].copy().filled(0)\n",
    "        count = np.where(tempCol > 0, 1, 0)\n",
    "        for j, colName_j in enumerate(colNames[i+stepSize::stepSize]):\n",
    "            tempCol += diffTable[colName_j].filled(0)\n",
    "            count += np.where(diffTable[colName_j].filled(0) > 0, 1, 0)\n",
    "        count = np.where(count > 0, count, np.nan)\n",
    "        diffTable.add_column(tempCol/count, name=f\"{colName_i.split('_')[0]}\")\n",
    "    return diffTable\n",
    "\n",
    "# Function to handle slit-losses\n",
    "def HandleSlitloss(lossData, photTable, specTable):\n",
    "    print(\"Calculating flux ratios...\")\n",
    "    ratioTable, fluxNames = CalcSlitRatio(photTable, specTable)\n",
    "    print(\"Interpolating slit-losses...\")\n",
    "    lossTables = CalcLossTable(lossData, fluxNames)\n",
    "    print(\"Calculating slit-loss factors...\")\n",
    "    diffTable = CalcDiffTable(ratioTable, lossTables)\n",
    "    diffTable = CalcAverageDiff(diffTable)\n",
    "    diffTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}differences.fits\", overwrite=True)\n",
    "    return diffTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93cbe8-a069-4aed-bab7-f29853b2717b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Importing data...\")\n",
    "\n",
    "# Directories\n",
    "try:\n",
    "    filterFolder\n",
    "    specFolder\n",
    "    outputFolder\n",
    "except NameError:\n",
    "    filterFolder = \"Throughputs/nircam_throughputs/mean_throughputs/\"\n",
    "    specFolder = \"Spectra/HST_Deep/prism_v1.5/\"\n",
    "    outputFolder = \"HST_Deep/prism_v1.5/\"\n",
    "\n",
    "# Spectra\n",
    "try:\n",
    "    specData\n",
    "except NameError:\n",
    "    specDir, specList, specNames = GetSpec()\n",
    "    specData = ImportSpec(specDir, specList, specNames)\n",
    "\n",
    "# Filters\n",
    "try:\n",
    "    filterData\n",
    "except NameError:\n",
    "    filterDir, filterList, filterNames = GetFilter()\n",
    "    filterData = ImportFilter(filterDir, filterList, filterNames)\n",
    "\n",
    "# Redshift catalogue\n",
    "try:\n",
    "    redshiftFile\n",
    "except NameError:\n",
    "    redshiftFolder = GetDirStruct() + \"Redshifts/Deep_HST.csv\"\n",
    "    redshiftID = \"ID\"\n",
    "    redshiftZ = \"Assigned_redshift\"\n",
    "    redshiftFile = tbl.Table.read(redshiftFolder)\n",
    "\n",
    "print(\"Plotting images...\")\n",
    "\n",
    "# PlotSpec(specData, specList, specNames)\n",
    "\n",
    "print(\"Calculating throughputs...\")\n",
    "\n",
    "specTable = LoopSpectra(specData, filterData, redshiftFile)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e54ef-a3c0-4109-ae5b-925daaaddcf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Importing data...\")\n",
    "\n",
    "# Directories\n",
    "try:\n",
    "    filterFolder\n",
    "    specFolder\n",
    "    outputFolder\n",
    "    photDir\n",
    "    lossFolder\n",
    "    lossPrefix\n",
    "    lossSuffix\n",
    "except NameError:\n",
    "    print(\"Defining directories...\")\n",
    "    filterFolder = \"Throughputs/nircam_throughputs/mean_throughputs/\"\n",
    "    specFolder = \"Spectra/HST_Deep/prism_v1.5/\"\n",
    "    outputFolder = \"HST_Deep/prism_v1.5/\"\n",
    "    photDir = \"../../Working_Directory/Apo_Phot/HST_Deep/\"\n",
    "    lossFolder = \"Slit-losses/HST/pathlosses_deep_R100/R100_v0/\"\n",
    "    lossPoints = [\"p01\", \"p02\", \"p03\"]\n",
    "    lossPrefix01 = \"pathlosses_correction_deep_hst_1x1_\"\n",
    "    lossPrefix02 = \"_idcat\"\n",
    "    lossExps = [\"exp00\", \"exp01\", \"exp02\"]\n",
    "    lossSuffix = \"_v0_point.txt\"\n",
    "\n",
    "# Spectra\n",
    "try:\n",
    "    specData\n",
    "except NameError:\n",
    "    print(\"Importing spectra...\")\n",
    "    specDir, specList, specNames = GetSpec()\n",
    "    specData = ImportSpec(specDir, specList, specNames)\n",
    "\n",
    "# Filters\n",
    "try:\n",
    "    filterData\n",
    "except NameError:\n",
    "    print(\"Importing filters...\")\n",
    "    filterDir, filterList, filterNames = GetFilter()\n",
    "    filterData = ImportFilter(filterDir, filterList, filterNames)\n",
    "    \n",
    "# Photometry\n",
    "try:\n",
    "    photTable\n",
    "except NameError:\n",
    "    print(\"Importing apodised fluxes...\")\n",
    "    photTable = ImportPhot(photDir)\n",
    "\n",
    "# Slitlosses\n",
    "try:\n",
    "    lossData\n",
    "except NameError:\n",
    "    print(\"Importing slitlosses...\")\n",
    "    lossDir, lossList = GrabSlitloss()\n",
    "    lossData = ImportSlitloss(lossDir, lossList, photTable)\n",
    "\n",
    "print(\"\\nFinding slit-losses ratios:\")\n",
    "\n",
    "diffTable = HandleSlitloss(lossData, photTable, specTable)\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066fc70-3447-4cfa-a0a1-1585a7410803",
   "metadata": {},
   "outputs": [],
   "source": [
    "float(filterNames[0][1] + '.' + filterNames[0][2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622488eb-ec1b-4056-8c86-3418083e442d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869525f-af58-44c3-93b0-936ae0fadf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPrefix = \"/Volumes/Storage/Slit-losses/HST/pathlosses_deep_R100/R100_v0/p01/pathlosses_correction_deep_hst_1x1_p01_exp00_idcat\"\n",
    "testSuffix = \"_v0_point.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf33aa-309e-465f-a208-c9e184698caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossesList = !bash -c \"ls {testPrefix}*{testSuffix}\"\n",
    "lossesList = [file.split('/')[-1] for file in lossesList]\n",
    "lossesList = [file.split('_')[-3] for file in lossesList]\n",
    "lossesNames = [file[5:11] for file in lossesList]\n",
    "lossesIDs = [int(file) for file in lossesNames]\n",
    "lossesTable = tbl.Table([lossesIDs, lossesNames], names=(\"ID\", \"Name\"))\n",
    "lossesTable.add_column((\"pathlosses_correction_deep_hst_1x1_p01_exp00_idcat_\" + lossesTable[\"Name\"] + testSuffix), name=(\"fileName\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3287fee-3d7f-453b-aa75-1cc067665a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossesTable.write(\"lossesTable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1a51d-bf36-4328-a4d0-9b817f23171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "photNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f26090-6a58-4a0f-b299-f93fdcc4dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "# plt.plot(Spectrum[\"Wavelength\"], Spectrum[\"Flux\"])\n",
    "# plt.plot(Filter[\"Wavelength\"], Filter[\"Throughput\"] * 10 **(-13))\n",
    "plt.plot(Filter_grid, Filter_conv * 10 ** (-13), color=\"green\")\n",
    "plt.plot(Filter_grid, Spectrum_flux, color=\"blue\")\n",
    "plt.plot(Filter_grid, Filter_conv * Spectrum_flux, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd018d-b194-4bad-97d6-34fe9161f83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
