{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b041040d-3945-45b5-a057-185a0eb4292c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing environment...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing environment...\")\n",
    "\n",
    "import platform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from astropy import table as tbl\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from scipy import constants as c\n",
    "from scipy import interpolate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d15e82a-4c21-4acf-a9d1-84a20a4516de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### All functions\n",
    "\n",
    "# Function to use appropriate OS directory structure\n",
    "def GetDirStruct():\n",
    "    match platform.system():\n",
    "        case \"Windows\":\n",
    "            dirPrefix = \"D:/\"\n",
    "        case \"Linux\" | \"Ubuntu\":\n",
    "            dirPrefix = \"/mnt/d/\"\n",
    "        case \"macOS\" | \"Darwin\":\n",
    "            dirPrefix = \"/Volumes/Storage/\"\n",
    "        case _:\n",
    "            raise Exception(f\"OS not recognised: \\\"{platform.system()}\\\". Please define a custom switch inside GetDirStruct().\")\n",
    "    return dirPrefix\n",
    "\n",
    "\n",
    "# Function to grab list of spectra in a directory\n",
    "def GetSpec():\n",
    "    dirPrefix = GetDirStruct()\n",
    "    specDir = dirPrefix + specFolder\n",
    "    specList = !bash -c \"ls {specDir}*1D.fits\"\n",
    "    specList = [file.split('/')[-1] for file in specList]\n",
    "    specNames = [file.split('_')[0] for file in specList]\n",
    "    return specDir, specList, specNames\n",
    "\n",
    "\n",
    "# Function to import files to dictionary\n",
    "def ImportSpec(specList, specDir, specNames):\n",
    "    specData = {}\n",
    "    for file, name in tqdm(zip(specList, specNames), desc=\"Importing spectra\", total=len(specList)):\n",
    "        specRaw = fits.open(specDir + file)\n",
    "        specFlux = specRaw[1].data * u.Jy\n",
    "        specWave = specRaw[9].data * u.m\n",
    "        specData[name] = tbl.QTable([specWave, specFlux], names=(\"Wavelength\", \"Flux\"))\n",
    "        specRaw.close()\n",
    "    return specData\n",
    "\n",
    "\n",
    "# Function to plot the spectra\n",
    "def PlotSpec(specData, specList, specNames):\n",
    "    !bash -c \"mkdir -p ../../Working_Directory/Apo_Phot_Utils/{outputFolder}plots\"\n",
    "    for file, name in tqdm(zip(specList, specNames), desc=\"Plotting galaxies\", total=len(specList)):\n",
    "        plt.plot(specData[name][\"Wavelength\"], specData[name][\"Flux\"])\n",
    "        plt.xscale('log')\n",
    "        plt.savefig(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}plots/{name}.png\")\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "# Function to grab filter curves\n",
    "def GetFilter():\n",
    "    dirPrefix = GetDirStruct()\n",
    "    filterDir = dirPrefix + filterFolder\n",
    "    filterList = !bash -c \"ls {filterDir}\"\n",
    "    filterList = [file.split('/')[-1] for file in filterList]\n",
    "    filterNames = [file.split('_')[0] for file in filterList]\n",
    "    filterData = {}\n",
    "    for file, name in tqdm(zip(filterList, filterNames), desc=\"Importing filters\", total=len(filterList)):\n",
    "        filterData[name] = tbl.QTable.read(filterDir + file, format=\"ascii\")\n",
    "        filterData[name][\"Microns\"].unit = u.um\n",
    "        filterData[name].rename_column(\"Microns\", \"Wavelength\")\n",
    "    return filterData\n",
    "\n",
    "# Function to parse tables and set any rows with NaNs to zero, to avoid errors\n",
    "def RemoveNaNs(tableObj):\n",
    "    for col in tableObj.colnames:\n",
    "        for x in range(0, len(tableObj[col]), 1):\n",
    "            if np.isnan(tableObj[col][x]):\n",
    "                tableObj[col][x] = 0\n",
    "    return tableObj\n",
    "\n",
    "# Function to interpolate datapoints\n",
    "def InterpFunc(funcXs, funcYs):\n",
    "    funcCubic = interpolate.interp1d(funcXs, funcYs, kind='cubic')\n",
    "    return funcCubic\n",
    "\n",
    "# Function to find grid overlap for convolutions of target using input\n",
    "def FindGrid(targetGrid, inputGrid, inputData):\n",
    "    # Sort all arrays\n",
    "    idxSorted = np.argsort(inputGrid)\n",
    "    sortedGrid = inputGrid[idxSorted]\n",
    "    sortedTarget = np.sort(targetGrid)\n",
    "    # Find first value in input that overlaps with target\n",
    "    if sortedGrid[0] < sortedTarget[0]:\n",
    "        idxLeft = np.searchsorted(sortedGrid, sortedTarget[0], side=\"right\")\n",
    "        if inputGrid[idxLeft-1] == sortedTarget[0]:\n",
    "            idxLeft -= 1\n",
    "    else:\n",
    "        idxLeft = 0\n",
    "    # Find last value in input that overlaps with target\n",
    "    if sortedGrid[-1] > sortedTarget[-1]:   \n",
    "        idxRight = np.searchsorted(sortedGrid, sortedTarget[-1], side=\"left\")\n",
    "        if inputGrid[idxRight] != sortedTarget[-1]:\n",
    "            idxRight -= 1\n",
    "    else:\n",
    "        idxRight = -1\n",
    "    # Return the section of input that overlaps target\n",
    "    overlapGrid = sortedGrid[idxLeft:idxRight]\n",
    "    overlapData = inputData[idxSorted][idxLeft:idxRight]\n",
    "    return overlapGrid, overlapData\n",
    "\n",
    "# Function to manage convolution calculation from first array onto second array\n",
    "def ConvolveFunc(firstXs, firstYs, secondXs, secondYs):\n",
    "    # Interpolate datapoints of first array\n",
    "    firstInterp = InterpFunc(firstXs.to(u.m), firstYs)\n",
    "    # Find relevant convolution grid for first array based on second array\n",
    "    secondOverlapGrid, secondOverlapData = FindGrid(firstXs, secondXs, secondYs)\n",
    "    # Convolve first array onto second array's grid\n",
    "    firstConvolved = firstInterp(secondOverlapGrid.to(u.m))\n",
    "    return firstConvolved, secondOverlapGrid, secondOverlapData\n",
    "\n",
    "# Function to convolve spectra and filters onto same grid\n",
    "def MergeGrids(specFile, filterFile):\n",
    "    specWave = specFile[\"Wavelength\"]\n",
    "    specFlux = specFile[\"Flux\"]\n",
    "    filterWave = filterFile[\"Wavelength\"]\n",
    "    filterThrough = filterFile[\"Throughput\"]\n",
    "    # Find mutual overlaps\n",
    "    specConvolved, filterOverlapGrid, filterOverlapData = ConvolveFunc(specWave, specFlux, filterWave, filterThrough)\n",
    "    filterConvolved, specOverlapGrid, specOverlapData = ConvolveFunc(filterWave, filterThrough, specWave, specFlux)\n",
    "    # Save as tables\n",
    "    specTable = tbl.Table([np.append(specOverlapGrid, filterOverlapGrid).to(u.m), np.append(specOverlapData, specConvolved*u.Jy)], names=(\"Wavelength\", \"Flux\"))\n",
    "    specTable.sort(\"Wavelength\")\n",
    "    filterTable = tbl.Table([np.append(filterOverlapGrid, specOverlapGrid).to(u.m), np.append(filterOverlapData, filterConvolved)], names=(\"Wavelength\", \"Throughput\"))\n",
    "    filterTable.sort(\"Wavelength\")\n",
    "    # Join tables\n",
    "    mergedTable = tbl.join(specTable, filterTable, keys=\"Wavelength\")\n",
    "    return mergedTable\n",
    "\n",
    "# Function to shift flux to photon space\n",
    "def ShiftPhotonSpace(mergedTable):\n",
    "    mergedTable[\"Flux\"] *= mergedTable[\"Wavelength\"]\n",
    "    return mergedTable\n",
    "\n",
    "# Function to integrate two functions on the same grid\n",
    "def IntegFunc(firstYs, secondYs, commonGrid):\n",
    "    funcIntegrated = np.trapz(firstYs * secondYs, x=commonGrid)\n",
    "    return funcIntegrated\n",
    "\n",
    "# Function to normalise the throughput to the correct zero-point\n",
    "def NormaliseValue(specTable, specValue):\n",
    "    specThrough = specTable[\"Throughput\"]\n",
    "    specGrid = specTable[\"Wavelength\"]\n",
    "    # norm_ref = 10**(48.6/(-2.5)) # reference zero magnitude\n",
    "    normRef = 1 * u.Jy.to(u.W / ((u.m)**2 * u.Hz)) * 10**(-6) # reference flat-value in f_nu\n",
    "    normYs = normRef * c.c / specGrid**2 * specGrid # not squared, f_lambda in photon_space\n",
    "    normValue = IntegFunc(specThrough, normYs, specGrid)\n",
    "    specNormed = specValue / normValue\n",
    "    return specNormed\n",
    "\n",
    "# Function to calculate throughput on a merged grid\n",
    "def CalcThroughput(mergedTable):\n",
    "    mergedWave = mergedTable[\"Wavelength\"]\n",
    "    mergedFlux = mergedTable[\"Flux\"]\n",
    "    mergedThrough = mergedTable[\"Throughput\"]\n",
    "    mergedOut = IntegFunc(mergedFlux, mergedThrough, mergedWave)\n",
    "    return mergedOut\n",
    "\n",
    "# Function to find throughput given a spectrum and filter\n",
    "def FindThroughput(specFile, filterFile):\n",
    "    # Convolve onto the same grid\n",
    "    mergedTable = MergeGrids(specFile, filterFile)\n",
    "    # Shift to photon space\n",
    "    mergedTable = ShiftPhotonSpace(mergedTable)\n",
    "    # Integrate through the filter\n",
    "    return CalcThroughput(mergedTable), mergedTable\n",
    "\n",
    "def BalmerBreak(specFile, specName, redshiftFile):\n",
    "    # Define regions\n",
    "    balmerLeftRange = np.array([3500, 3650]) * u.angstrom\n",
    "    balmerRightRange = np.array([3800, 3950]) * u.angstrom\n",
    "    # Grab relevant grids\n",
    "    for row in range(0, len(redshiftFile), 1):\n",
    "        if int(specName) == int(redshiftFile[row][redshiftID]) and redshiftFile[row][redshiftZ] > 0:\n",
    "            redshiftFactor = 1 + redshiftFile[row][redshiftZ]\n",
    "            break\n",
    "        else:\n",
    "            redshiftFactor = np.nan\n",
    "    if redshiftFactor != 0:\n",
    "        balmerLeftWave, balmerLeftSpec = FindGrid(balmerLeftRange, specFile[\"Wavelength\"]/redshiftFactor, specFile[\"Flux\"]*redshiftFactor)\n",
    "        balmerRightWave, balmerRightSpec = FindGrid(balmerRightRange, specFile[\"Wavelength\"]/redshiftFactor, specFile[\"Flux\"]*redshiftFactor)\n",
    "        # Shift to photon space\n",
    "        balmerLeftSpec *= balmerLeftWave\n",
    "        balmerRightSpec *= balmerRightWave\n",
    "        # Calculate average flux\n",
    "        balmerLeftVal = np.sum(balmerLeftSpec) / len(balmerLeftSpec)\n",
    "        balmerRightVal = np.sum(balmerRightSpec) / len(balmerRightSpec)\n",
    "        # Calculate ratio\n",
    "        balmerRatio = balmerRightVal/balmerLeftVal\n",
    "        balmerVals = [balmerLeftVal, balmerRightVal, balmerRatio]\n",
    "    return balmerVals\n",
    "\n",
    "# Function to loop through filters and balmer breaks for one spectrum\n",
    "def HandleSpectrum(specFile, specName, filterData, redshiftFile):\n",
    "    specValues = []\n",
    "    for filter in filterData.values():\n",
    "        specValue, specTable = FindThroughput(specFile, filter)\n",
    "        specValues += [NormaliseValue(specTable, specValue)]\n",
    "    specValues += BalmerBreak(specFile, specName, redshiftFile)\n",
    "    return specValues\n",
    "\n",
    "# Function to loop through each spectrum and save values to a table\n",
    "def LoopSpectra(specData, filterData, redshiftFile):\n",
    "    !bash -c \"mkdir -p ../../Working_Directory/Apo_Phot_Utils/{outputFolder}\"\n",
    "    rows = []\n",
    "    for specName, specFull in tqdm(zip(specData.keys(), specData.values()), desc=\"Galaxies\", total=len(specData.keys())):\n",
    "        rows += [[int(specName)] + HandleSpectrum(specFull, specName, filterData, redshiftFile)]\n",
    "    names = [\"ID\"] + list(filterData.keys()) + [\"Balmer_left\", \"Balmer_right\", \"Balmer_ratio\"]\n",
    "    outTable = tbl.Table(rows=rows, names=names)\n",
    "    outTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}throughputs.fits\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd93cbe8-a069-4aed-bab7-f29853b2717b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f358df7e744048cfb2689795fc47d038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing spectra:   0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efea8f3cb2764394a1b286d901b4ca53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing filters:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2fc0e1a68c4c4998f599e135af25f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning spectra:   0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f167f6f25a54fb7aac692ec7e313c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning filters:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a575d3f9f84898a764c5c96406baef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plotting galaxies:   0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating throughputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4415bbd18d44658e0ee2d055e37bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Galaxies:   0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing data...\")\n",
    "\n",
    "# Directories\n",
    "try:\n",
    "    filterFolder\n",
    "    specFolder\n",
    "    outputFolder\n",
    "    comparisonFile\n",
    "except NameError:\n",
    "    filterFolder = \"Throughputs/nircam_throughputs/mean_throughputs/\"\n",
    "    specFolder = \"Spectra/HST_Medium/prism_clear_v1.5/prism_clear/\"\n",
    "    outputFolder = \"HST_Medium/prism_clear_v1.5/\"\n",
    "\n",
    "# Spectra\n",
    "try:\n",
    "    specData\n",
    "except NameError:\n",
    "    specDir, specList, specNames = GetSpec()\n",
    "    specData = ImportSpec(specList, specDir, specNames)\n",
    "\n",
    "# Filters\n",
    "try:\n",
    "    filterData\n",
    "except NameError:\n",
    "    filterData = GetFilter()\n",
    "\n",
    "# Redshift catalogue\n",
    "try:\n",
    "    redshiftFile\n",
    "except NameError:\n",
    "    redshiftFolder = GetDirStruct() + \"Redshifts/Medium_HST.csv\"\n",
    "    redshiftID = \"ID\"\n",
    "    redshiftZ = \"Assigned_redshift\"\n",
    "    redshiftFile = tbl.Table.read(redshiftFolder)\n",
    "\n",
    "print(\"Cleaning data...\")\n",
    "\n",
    "for spectrum in tqdm(specData.values(), desc=\"Cleaning spectra\"):\n",
    "    spectrum = RemoveNaNs(spectrum)\n",
    "for filterFile in tqdm(filterData.values(), desc=\"Cleaning filters\"):\n",
    "    filterFile = RemoveNaNs(filterFile)\n",
    "\n",
    "print(\"Plotting images...\")\n",
    "\n",
    "PlotSpec(specData, specList, specNames)\n",
    "\n",
    "print(\"Calculating throughputs...\")\n",
    "\n",
    "LoopSpectra(specData, filterData, redshiftFile)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f26090-6a58-4a0f-b299-f93fdcc4dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "# plt.plot(Spectrum[\"Wavelength\"], Spectrum[\"Flux\"])\n",
    "# plt.plot(Filter[\"Wavelength\"], Filter[\"Throughput\"] * 10 **(-13))\n",
    "plt.plot(Filter_grid, Filter_conv * 10 ** (-13), color=\"green\")\n",
    "plt.plot(Filter_grid, Spectrum_flux, color=\"blue\")\n",
    "plt.plot(Filter_grid, Filter_conv * Spectrum_flux, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd018d-b194-4bad-97d6-34fe9161f83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
