{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041040d-3945-45b5-a057-185a0eb4292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing environment...\")\n",
    "\n",
    "import platform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from astropy import table as tbl\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy import constants as c\n",
    "from scipy import interpolate\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3f9d6-7800-459d-ac5b-6121e7895b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 * u.nJy * c.c * u.m**2) * u.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f0582-1e2b-4c8f-bedb-0ae48e6c947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 * u.Jy.si * c.c * u.m**2).value * u.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4305319-3a69-4a7d-b04e-52bfff04043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.Jy.si * u.m**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd5b501-7b8d-49f7-86df-5d70f357397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.Jy.si * c.c / u.m**2 * u.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3f4af-750b-40c2-a7cf-94a6fa2983df",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.Jy.si.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15e82a-4c21-4acf-a9d1-84a20a4516de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### All functions\n",
    "\n",
    "\n",
    "# Function to parse tables and set any rows with NaNs to zero, to avoid errors\n",
    "def RemoveNaNs(tableObj):\n",
    "    for col in tableObj.colnames:\n",
    "        for x in range(0, len(tableObj[col]), 1):\n",
    "            if np.isnan(tableObj[col][x]):\n",
    "                tableObj[col][x] = 0\n",
    "    return tableObj\n",
    "\n",
    "\n",
    "# Function to use appropriate OS directory structure\n",
    "def GetDirStruct():\n",
    "    match platform.system():\n",
    "        case \"Windows\":\n",
    "            dirPrefix = \"D:/\"\n",
    "        case \"Linux\" | \"Ubuntu\":\n",
    "            dirPrefix = \"/mnt/d/\"\n",
    "        case \"macOS\" | \"Darwin\":\n",
    "            dirPrefix = \"/Volumes/Storage/\"\n",
    "        case _:\n",
    "            raise Exception(f\"OS not recognised: \\\"{platform.system()}\\\". Please define a custom switch inside GetDirStruct().\")\n",
    "    return dirPrefix\n",
    "\n",
    "\n",
    "# Function to grab list of spectra in a directory\n",
    "def GetSpec():\n",
    "    dirPrefix = GetDirStruct()\n",
    "    specDir = dirPrefix + specFolder\n",
    "    specList = !bash -c \"ls {specDir}*1D.fits\"\n",
    "    specList = [file.split('/')[-1] for file in specList]\n",
    "    specNames = [file.split('_')[0] for file in specList]\n",
    "    return specDir, specList, specNames\n",
    "\n",
    "\n",
    "# Function to import files to dictionary\n",
    "def ImportSpec(specDir, specList, specNames):\n",
    "    specData = {}\n",
    "    for file, name in tqdm(list(zip(specList, specNames)), desc=\"Importing spectra\"):\n",
    "        specRaw = fits.open(specDir + file)\n",
    "        specFlux = specRaw[1].data * u.Jy\n",
    "        specWave = specRaw[9].data * u.m\n",
    "        specData[name] = tbl.QTable([specWave, specFlux], names=(\"Wavelength\", \"Flux\"))\n",
    "        specData[name] = RemoveNaNs(specData[name])\n",
    "        specRaw.close()\n",
    "    return specData\n",
    "\n",
    "\n",
    "# Function to plot the spectra\n",
    "def PlotSpec(specData, specList, specNames):\n",
    "    !bash -c \"mkdir -p ../../Working_Directory/Apo_Phot_Utils/{outputFolder}/plots/spectra/\"\n",
    "    for file, name in tqdm(zip(specList, specNames), desc=\"Plotting spectra\", total=len(specList)):\n",
    "        plt.plot(specData[name][\"Wavelength\"], specData[name][\"Flux\"])\n",
    "        plt.xscale('log')\n",
    "        plt.savefig(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}plots/spectra/{name}.png\")\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "# Function to grab list of filter curves\n",
    "def GetFilter():\n",
    "    dirPrefix = GetDirStruct()\n",
    "    filterDir = dirPrefix + filterFolder\n",
    "    filterList = !bash -c \"ls {filterDir}\"\n",
    "    filterList = [file.split('/')[-1] for file in filterList]\n",
    "    filterNames = [file.split('_')[0] for file in filterList]\n",
    "    return filterDir, filterList, filterNames\n",
    "\n",
    "# Function to import filters to a dictionary\n",
    "def ImportFilter(filterDir, filterList, filterNames):\n",
    "    filterData = {}\n",
    "    for file, name in tqdm(zip(filterList, filterNames), desc=\"Importing filters\", total=len(filterList)):\n",
    "        filterData[name] = tbl.QTable.read(filterDir + file, format=\"ascii\")\n",
    "        filterData[name][\"Microns\"].unit = u.um\n",
    "        filterData[name].rename_column(\"Microns\", \"Wavelength\")\n",
    "        filterData[name][\"Throughput\"].unit = u.dimensionless_unscaled\n",
    "        filterData[name] = RemoveNaNs(filterData[name])\n",
    "    return filterData\n",
    "\n",
    "# Function to interpolate datapoints\n",
    "def InterpFunc(funcXs, funcYs):\n",
    "    funcCubic = interpolate.interp1d(funcXs, funcYs, kind='cubic')\n",
    "    return funcCubic\n",
    "\n",
    "# Function to find grid overlap for convolutions of target using input\n",
    "def FindGrid(targetGrid, inputGrid, inputData):\n",
    "    # Sort all arrays\n",
    "    idxSorted = np.argsort(inputGrid)\n",
    "    sortedGrid = inputGrid[idxSorted]\n",
    "    sortedTarget = np.sort(targetGrid)\n",
    "    # Find first value in input that overlaps with target\n",
    "    if sortedGrid[0] < sortedTarget[0]:\n",
    "        idxLeft = np.searchsorted(sortedGrid, sortedTarget[0], side=\"right\")\n",
    "        if inputGrid[idxLeft-1] == sortedTarget[0]:\n",
    "            idxLeft -= 1\n",
    "    else:\n",
    "        idxLeft = 0\n",
    "    # Find last value in input that overlaps with target\n",
    "    if sortedGrid[-1] > sortedTarget[-1]:   \n",
    "        idxRight = np.searchsorted(sortedGrid, sortedTarget[-1], side=\"left\")\n",
    "        if inputGrid[idxRight] != sortedTarget[-1]:\n",
    "            idxRight -= 1\n",
    "    else:\n",
    "        idxRight = -1\n",
    "    # Return the section of input that overlaps target\n",
    "    overlapGrid = sortedGrid[idxLeft:idxRight]\n",
    "    overlapData = inputData[idxSorted][idxLeft:idxRight]\n",
    "    return overlapGrid, overlapData\n",
    "\n",
    "# Function to manage convolution calculation from first array onto second array\n",
    "def ConvolveFunc(firstXs, firstYs, secondXs, secondYs):\n",
    "    # Interpolate datapoints of first array\n",
    "    firstInterp = InterpFunc(firstXs.to(u.m), firstYs)\n",
    "    # Find relevant convolution grid for first array based on second array\n",
    "    secondOverlapGrid, secondOverlapData = FindGrid(firstXs, secondXs, secondYs)\n",
    "    # Convolve first array onto second array's grid\n",
    "    firstConvolved = firstInterp(secondOverlapGrid.to(u.m)) * firstYs.unit\n",
    "    return firstConvolved, secondOverlapGrid, secondOverlapData\n",
    "\n",
    "# Function to convolve spectra and filters onto same grid\n",
    "def MergeGrids(specFile, filterFile):\n",
    "    specWave = specFile[\"Wavelength\"]\n",
    "    specFlux = specFile[\"Flux\"]\n",
    "    filterWave = filterFile[\"Wavelength\"]\n",
    "    filterThrough = filterFile[\"Throughput\"]\n",
    "    # Find mutual overlaps\n",
    "    specConvolved, filterOverlapGrid, filterOverlapData = ConvolveFunc(specWave, specFlux, filterWave, filterThrough)\n",
    "    filterConvolved, specOverlapGrid, specOverlapData = ConvolveFunc(filterWave, filterThrough, specWave, specFlux)\n",
    "    # Save as tables\n",
    "    specTable = tbl.QTable([np.append(specOverlapGrid, filterOverlapGrid).to(u.m), np.append(specOverlapData, specConvolved)], names=(\"Wavelength\", \"Flux\"))\n",
    "    specTable.sort(\"Wavelength\")\n",
    "    filterTable = tbl.QTable([np.append(filterOverlapGrid, specOverlapGrid).to(u.m), np.append(filterOverlapData, filterConvolved)], names=(\"Wavelength\", \"Throughput\"))\n",
    "    filterTable.sort(\"Wavelength\")\n",
    "    # Join tables\n",
    "    mergedTable = tbl.join(specTable, filterTable, keys=\"Wavelength\")\n",
    "    return mergedTable\n",
    "\n",
    "# Function to shift flux to photon space\n",
    "def ShiftPhotonSpace(mergedTable):\n",
    "    mergedTable[\"Flux\"] *= mergedTable[\"Wavelength\"]\n",
    "    return mergedTable\n",
    "\n",
    "# Function to integrate two functions on the same grid\n",
    "def IntegFunc(firstYs, secondYs, commonGrid):\n",
    "    funcIntegrated = np.trapz(firstYs * secondYs, x=commonGrid) # * (firstYs.unit * secondYs.unit * commonGrid.unit)\n",
    "    return funcIntegrated\n",
    "\n",
    "# Function to calculate throughput on a merged grid\n",
    "def CalcThroughput(mergedTable):\n",
    "    mergedWave = mergedTable[\"Wavelength\"]\n",
    "    mergedFlux = mergedTable[\"Flux\"]\n",
    "    mergedThrough = mergedTable[\"Throughput\"]\n",
    "    mergedOut = IntegFunc(mergedFlux, mergedThrough, mergedWave)\n",
    "    return mergedOut\n",
    "\n",
    "# Function to find throughput given a spectrum and filter\n",
    "def FindThroughput(specFile, filterFile):\n",
    "    # Convolve onto the same grid\n",
    "    mergedTable = MergeGrids(specFile, filterFile)\n",
    "    # Shift to photon space\n",
    "    mergedTable = ShiftPhotonSpace(mergedTable)\n",
    "    # Integrate through the filter\n",
    "    return CalcThroughput(mergedTable), mergedTable\n",
    "\n",
    "# Function to normalise the throughput to the correct zero-point\n",
    "def NormaliseValue(specTable, specValue):\n",
    "    specThrough = specTable[\"Throughput\"]\n",
    "    specGrid = specTable[\"Wavelength\"]\n",
    "    # norm_ref = 10**(48.6/(-2.5)) # reference zero magnitude\n",
    "    normRef = (1 * u.Jy).si.value #* 10**(-9) # reference flat-value in f_nu\n",
    "    # print(normRef)\n",
    "    normYs = (normRef * c.c / specGrid**2 * specGrid).value * specGrid.unit # reference flat-value in photon space, units removed\n",
    "    # print(normYs)\n",
    "    normValue = IntegFunc(specThrough, normYs, specGrid)\n",
    "    # print(normValue)\n",
    "    specNormed = (specValue / normValue).to(u.nJy)\n",
    "    return specNormed\n",
    "\n",
    "def BalmerBreak(specFile, specName, redshiftFile):\n",
    "    # Define regions\n",
    "    balmerLeftRange = np.array([3500, 3650]) * u.angstrom\n",
    "    balmerRightRange = np.array([3800, 3950]) * u.angstrom\n",
    "    # Grab relevant grids\n",
    "    for row in range(0, len(redshiftFile), 1):\n",
    "        if int(specName) == int(redshiftFile[row][redshiftID]) and redshiftFile[row][redshiftZ] > 0:\n",
    "            redshiftFactor = 1 + redshiftFile[row][redshiftZ]\n",
    "            break\n",
    "        else:\n",
    "            redshiftFactor = np.nan\n",
    "    if redshiftFactor != 0:\n",
    "        balmerLeftWave, balmerLeftSpec = FindGrid(balmerLeftRange, specFile[\"Wavelength\"]/redshiftFactor, specFile[\"Flux\"]*redshiftFactor)\n",
    "        balmerLeftTable = tbl.QTable([balmerLeftWave, balmerLeftSpec], names=(\"Wavelength\", \"Flux\"))\n",
    "        balmerRightWave, balmerRightSpec = FindGrid(balmerRightRange, specFile[\"Wavelength\"]/redshiftFactor, specFile[\"Flux\"]*redshiftFactor)\n",
    "        balmerRightTable = tbl.QTable([balmerRightWave, balmerRightSpec], names=(\"Wavelength\", \"Flux\"))\n",
    "        # Shift to photon space\n",
    "        balmerLeftTable = ShiftPhotonSpace(balmerLeftTable)\n",
    "        balmerRightTable = ShiftPhotonSpace(balmerRightTable)\n",
    "        # Calculate average flux\n",
    "        balmerLeftVal = np.sum(balmerLeftTable[\"Flux\"]) / len(balmerLeftTable[\"Flux\"])\n",
    "        balmerRightVal = np.sum(balmerRightTable[\"Flux\"]) / len(balmerRightTable[\"Flux\"])\n",
    "        # Calculate ratio\n",
    "        balmerRatio = balmerRightVal/balmerLeftVal\n",
    "        balmerVals = [balmerLeftVal, balmerRightVal, balmerRatio]\n",
    "    return balmerVals\n",
    "\n",
    "# Function to loop through filters and balmer breaks for one spectrum\n",
    "def HandleSpectrum(specFile, specName, filterData, redshiftFile):\n",
    "    specValues = []\n",
    "    for filterFile in filterData.values():\n",
    "        specValue, specTable = FindThroughput(specFile, filterFile)\n",
    "        specValues += [NormaliseValue(specTable, specValue), np.nan]\n",
    "    specValues += BalmerBreak(specFile, specName, redshiftFile)\n",
    "    return specValues\n",
    "\n",
    "# Function to loop through each spectrum and save values to a table\n",
    "def LoopSpectra(specData, filterData, redshiftFile):\n",
    "    !bash -c \"mkdir -p ../../Working_Directory/Apo_Phot_Utils/{outputFolder}\"\n",
    "    rows = []\n",
    "    for specName, specFull in tqdm(zip(specData.keys(), specData.values()), desc=\"Calculating throughputs\", total=len(specData.keys())):\n",
    "        rows += [[int(specName)] + HandleSpectrum(specFull, specName, filterData, redshiftFile)]\n",
    "    names = [\"ID\"] + list(chain.from_iterable([[key + \" Through\", key + \" Through Error\"] for key in filterData.keys()])) + [\"Balmer_left\", \"Balmer_right\", \"Balmer_ratio\"]\n",
    "    outTable = tbl.Table(rows=rows, names=names)\n",
    "    outTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}throughputs.fits\", overwrite=True)\n",
    "    return outTable\n",
    "\n",
    "# Function to import photometry files\n",
    "def ImportPhot():\n",
    "    photList = !bash -c \"ls {photDir}/* | grep -v \\\"summary.fits\\\" | grep -v \\\"parameters.fits\\\"\"\n",
    "    photList = [file.split('/')[-1] for file in photList]\n",
    "    photTables = {}\n",
    "    for file in tqdm(photList, desc=\"Importing apodised fluxes\"):\n",
    "        pointingNum = int(file.split('_')[-1].split('.')[0])\n",
    "        photBand = file.split('_')[0]\n",
    "        photRaw = tbl.QTable.read(f\"{photDir}/{file}\")\n",
    "        try:\n",
    "            photTables[pointingNum]\n",
    "        except KeyError:\n",
    "            photTables[pointingNum] = tbl.QTable()\n",
    "            photTables[pointingNum].add_column(photRaw[\"ID\"], name=\"ID\")\n",
    "        finally:\n",
    "            tempTable = tbl.QTable()\n",
    "            tempTable.add_columns([photRaw[\"ID\"], photRaw[\"Actual Flux\"], photRaw[\"Flux Error\"]], names=[\"ID\", f\"{photBand} Flux\", f\"{photBand} Error\"])\n",
    "            photTables[pointingNum] = tbl.join(photTables[pointingNum], tempTable, keys=\"ID\", join_type=\"left\")\n",
    "    return photTables\n",
    "\n",
    "# Function to import Astrometry\n",
    "def ImportAstro():\n",
    "    astroTables = {}\n",
    "    dirPrefix = GetDirStruct()\n",
    "    for slit, point in tqdm(list(zip(slitNums, pointNums)), desc=\"Importing astrometry\"):\n",
    "            sourceList = tbl.QTable.read(f\"{dirPrefix}/Astrometry/{astroDir}/{pointFolder}/{pointPrefix}{point}{pointSuffix}\", format=\"ascii\")\n",
    "            sourceAstro = tbl.QTable.read(f\"{dirPrefix}/Astrometry/{astroDir}/{slitFolder}/{slitPrefix}{slit}{slitSuffix}\", format=\"ascii\")\n",
    "            astroTables[point] = tbl.join(sourceList, sourceAstro, keys=\"ID\")\n",
    "    return astroTables\n",
    "\n",
    "# Function to grab list of slitloss corrections\n",
    "def GrabSlitloss():\n",
    "    lossDir = GetDirStruct() + lossFolder\n",
    "    lossList = {}\n",
    "    for lossPoint in tqdm(lossPoints, desc=\"Grabbing slitlosses\"):\n",
    "        lossList[lossPoint] = {}\n",
    "        for lossExp in tqdm(lossExps, desc=\"Extracting IDs\", leave=False):\n",
    "            lossNames = !bash -c \"ls {lossDir}/{lossPoint}/{lossPrefix01}{lossPoint}_{lossExp}{lossPrefix02}*{lossSuffix}\"\n",
    "            # lossList = !bash -c \"ls {lossDir}/{lossPrefix}*{lossSuffix}\"\n",
    "            lossNames = [f\"{file.split('/')[-2]}/{file.split('/')[-1]}\" for file in lossNames]\n",
    "            lossIDs = [int(file.split('_')[-3].split('idcat')[-1]) for file in lossNames]\n",
    "            lossList[lossPoint][lossExp] = tbl.Table([lossIDs, lossNames], names=(\"ID\", \"Name\"))\n",
    "    return lossDir, lossList\n",
    "\n",
    "# Function to import slitloss corrections\n",
    "def ImportSlitloss(lossDir, lossList, photTables):\n",
    "    lossData = {}\n",
    "    for pointNum, pointName in tqdm(list(zip(pointNums, lossPoints)), desc=\"Importing slitlosses\"):\n",
    "        IDList = tbl.Table([photTables[pointNum][\"ID\"]])\n",
    "        lossData[pointName] = {}\n",
    "        for lossExp in tqdm(lossList[pointName].keys(), desc=\"Parsing exposures\", leave=False):\n",
    "            lossData[pointName][lossExp] = {}\n",
    "            lossData[pointName][lossExp][\"Index\"] = tbl.join(lossList[pointName][lossExp], IDList, keys=\"ID\")\n",
    "            for row in tqdm(range(0, len(lossData[pointName][lossExp][\"Index\"]), 1), desc=\"Matching IDs\", leave=False):\n",
    "                galID = lossData[pointName][lossExp][\"Index\"][row][\"ID\"]\n",
    "                galName = lossData[pointName][lossExp][\"Index\"][row][\"Name\"]\n",
    "                lossData[pointName][lossExp][galID] = tbl.QTable.read(lossDir + galName, format=\"ascii\")\n",
    "                lossData[pointName][lossExp][galID].rename_column(\"col1\", \"Slitloss\")\n",
    "                lossData[pointName][lossExp][galID].rename_column(\"col2\", \"Wavelength\")\n",
    "                lossData[pointName][lossExp][galID][\"Slitloss\"].unit = u.dimensionless_unscaled\n",
    "                lossData[pointName][lossExp][galID][\"Wavelength\"].unit = u.um\n",
    "            del lossData[pointName][lossExp][\"Index\"]\n",
    "    return lossData\n",
    "\n",
    "# Function to calculate photometry ratios\n",
    "def CalcSlitRatio(photTable, specTable, pointNum):\n",
    "    combTable = tbl.join(photTable, specTable, keys=\"ID\")\n",
    "    firstFlux = 1\n",
    "    firstThrough = len(photTable.colnames)\n",
    "    fluxCols = combTable.colnames[firstFlux:firstThrough:2]\n",
    "    throughCols = combTable.colnames[firstThrough::2]\n",
    "    ratioTable = tbl.QTable([combTable[\"ID\"]])\n",
    "    fluxNames = []\n",
    "    for col in combTable.colnames[1:]:\n",
    "        combTable[col] = np.where(combTable[col] > 0, combTable[col], np.nan)\n",
    "    for fluxCol in fluxCols:\n",
    "        fluxName = fluxCol.split()[0]\n",
    "        for throughCol in throughCols:\n",
    "            throughName = throughCol.split()[0]\n",
    "            if fluxName == throughName:\n",
    "                ratioTable.add_columns([combTable[fluxCol], combTable[throughCol], combTable[fluxCol]/combTable[throughCol], np.nan], names=(fluxCol, throughCol, f\"{fluxName} Ratio\", f\"{fluxName} Ratio Error\"))\n",
    "                fluxNames += [fluxName]\n",
    "    ratioTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}ratios_{pointNum}.fits\", overwrite=True)\n",
    "    return ratioTable, fluxNames\n",
    "\n",
    "# Function to calculate slit-losses at centre of filters\n",
    "def CalcLossTable(lossData, fluxNames, lossTables, pointName):\n",
    "    lossTables[pointName] = {}\n",
    "    for exposure in lossData.keys():\n",
    "        rows = []\n",
    "        for galaxy in lossData[exposure].keys():\n",
    "            row = []\n",
    "            row += [galaxy]\n",
    "            lossInterpolated = interpolate.interp1d(lossData[exposure][galaxy][\"Wavelength\"], lossData[exposure][galaxy][\"Slitloss\"])\n",
    "            for fluxName in fluxNames:\n",
    "                centralWave = float(fluxName[1] + '.' + fluxName[2:4]) * u.um\n",
    "                centralLoss = lossInterpolated(centralWave)\n",
    "                row += [1/centralLoss * u.dimensionless_unscaled]\n",
    "            rows += [row]\n",
    "        names = [\"ID\"] + [f\"{fluxName} slitloss\" for fluxName in fluxNames]\n",
    "        lossTables[pointName][exposure] = tbl.QTable(rows=rows, names=names)\n",
    "    return lossTables\n",
    "\n",
    "# Function to calculate slit-loss factor between photometry and model\n",
    "def CalcDiffTable(ratioTable, lossTables, pointName):\n",
    "    diffTable = tbl.QTable([ratioTable[\"ID\"]])\n",
    "    for exposure in lossTables.keys():\n",
    "        matchedTable = tbl.join(ratioTable, lossTables[exposure], keys=\"ID\")\n",
    "        firstRatio = 3\n",
    "        firstLoss = len(ratioTable.colnames)\n",
    "        ratioNames = matchedTable.colnames[firstRatio:firstLoss:4]\n",
    "        lossNames = matchedTable.colnames[firstLoss:]\n",
    "        tempTable = tbl.QTable([matchedTable[\"ID\"]])\n",
    "        for ratioName in ratioNames:\n",
    "            for lossName in lossNames:\n",
    "                if ratioName.split()[0] == lossName.split()[0]:\n",
    "                    tempTable.add_column(matchedTable[ratioName]/matchedTable[lossName], name=f\"{ratioName.split()[0]}_{exposure}_Diff\")\n",
    "        diffTable = tbl.join(diffTable, tempTable, keys=\"ID\", join_type='outer')\n",
    "    diffTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}differences_{pointName}_detailed.fits\", overwrite=True)\n",
    "    return diffTable\n",
    "\n",
    "# Function to append average differences across pointings and exposures\n",
    "def CalcAverageDiff(diffTable, astroTable, pointName):\n",
    "    colNames = diffTable.colnames[1:]\n",
    "    # k = len(colNames)\n",
    "    for i, colName_i in enumerate(colNames):\n",
    "        stepSize = 0\n",
    "        jumpSize = 0\n",
    "        # for j, colName_j in enumerate(colNames[i+1:]):\n",
    "        #     if colName_i.split('_')[0:2] == colName_j.split('_')[0:2]:\n",
    "        #         stepSize = j + 1\n",
    "        #         break\n",
    "        # for j, colName_j in enumerate(colNames[i+stepSize::stepSize]):\n",
    "        #     if colName_i.split('_')[0] == colName_j.split('_')[0] and colName_i.split('_')[1] != colName_j.split('_')[1]:\n",
    "        #         jumpSize = (j + 1) * stepSize\n",
    "        #         break\n",
    "        for j, colName_j in enumerate(colNames[i+1:]):\n",
    "            if colName_i.split('_')[0] == colName_j.split('_')[0]:\n",
    "                stepSize = j + 1\n",
    "                jumpSize = len(colNames) # added to adjust for commented lines\n",
    "                break\n",
    "        if 0 not in [stepSize, jumpSize]:\n",
    "            k = 0\n",
    "            break\n",
    "    # while k < len(colNames):\n",
    "    #     for i, colName_i in enumerate(colNames[k:k+stepSize:1]):\n",
    "    #         tempCol = diffTable[colName_i].copy().filled(0)\n",
    "    #         count = np.where(tempCol > 0, 1, 0)\n",
    "    #         for j, colName_j in enumerate(colNames[k+i+stepSize:k+i+jumpSize:stepSize]):\n",
    "    #             tempCol += diffTable[colName_j].filled(0)\n",
    "    #             count += np.where(diffTable[colName_j].filled(0) > 0, 1, 0)\n",
    "    #         count = np.where(count > 0, count, np.nan)\n",
    "    #         diffTable.add_column(tempCol/count, name=f\"{colName_i.split('_')[0]}_{colName_i.split('_')[1]}\")\n",
    "    #     k += jumpSize\n",
    "    # for i, colName_i in enumerate(colNames[0:stepSize]):\n",
    "    #     tempCol = diffTable[colName_i].copy().filled(0)\n",
    "    #     count = np.where(tempCol > 0, 1, 0)\n",
    "    #     for j, colName_j in enumerate(colNames[i+stepSize::stepSize]):\n",
    "    #         tempCol += diffTable[colName_j].filled(0)\n",
    "    #         count += np.where(diffTable[colName_j].filled(0) > 0, 1, 0)\n",
    "    #     count = np.where(count > 0, count, np.nan)\n",
    "    #     diffTable.add_column(tempCol/count, name=f\"{colName_i.split('_')[0]}\")\n",
    "    tempTable = tbl.QTable([diffTable[\"ID\"]])\n",
    "    while k < len(colNames):\n",
    "        for i, colName_i in enumerate(colNames[k:k+stepSize:1]):\n",
    "            tempCol = diffTable[colName_i].copy()\n",
    "            count = np.where(tempCol > 0, 1, 0)\n",
    "            for j, colName_j in enumerate(colNames[k+i+stepSize:k+i:stepSize]):\n",
    "                tempCol += diffTable[colName_j]\n",
    "                count += np.where(diffTable[colName_j] > 0, 1, 0)\n",
    "            count = np.where(count > 0, count, np.nan)\n",
    "            tempTable.add_column(tempCol/count, name=f\"{colName_i.split('_')[0]}_Diff\")\n",
    "        k += jumpSize\n",
    "    diffTable = tbl.join(tempTable, astroTable, keys=\"ID\", join_type=\"left\")\n",
    "    diffTable.write(f\"../../Working_Directory/Apo_Phot_Utils/{outputFolder}differences_{pointName}.fits\", overwrite=True)\n",
    "    return diffTable\n",
    "\n",
    "# Function to handle slit-losses\n",
    "def HandleSlitloss(lossData, photTables, astroTables, specTable):\n",
    "    lossTables = {}\n",
    "    diffTables = {}\n",
    "    ratioTables = {}\n",
    "    for pointNum, pointName in tqdm(list(zip(pointNums, lossPoints)), desc=\"Calculating difference factors\"):\n",
    "        ratioTable, fluxNames = CalcSlitRatio(photTables[pointNum], specTable, pointNum)\n",
    "        lossTables = CalcLossTable(lossData[pointName], fluxNames, lossTables, pointName)\n",
    "        diffTable = CalcDiffTable(ratioTable, lossTables[pointName], pointName)\n",
    "        diffTable = CalcAverageDiff(diffTable, astroTables[pointNum], pointName)\n",
    "        ratioTables[pointNum] = ratioTable\n",
    "        diffTables[pointNum] = diffTable\n",
    "    return ratioTables, lossTables, diffTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69e54ef-a3c0-4109-ae5b-925daaaddcf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "try:\n",
    "    filterFolder\n",
    "    specFolder\n",
    "    outputFolder\n",
    "    photDir\n",
    "    slitNums\n",
    "    pointNums\n",
    "    lossFolder\n",
    "    lossPrefix\n",
    "    lossSuffix\n",
    "except NameError:\n",
    "    print(\"Defining directories...\")\n",
    "    filterFolder = \"Throughputs/nircam_throughputs/mean_throughputs/\"\n",
    "    specFolder = \"Spectra/HST_Deep/prism_v1.5/\"\n",
    "    outputFolder = \"HST_Deep/prism_v1.5/\"\n",
    "    photDir = \"../../Working_Directory/Apo_Phot/HST_Deep/\"\n",
    "    astroDir = \"HST_Deep/for_emma_v2a_clean2/prism_trial_01_v2a_clean2/\"\n",
    "    slitFolder = \"m_make_output/\"\n",
    "    slitPrefix = \"table\"\n",
    "    slitSuffix = \".txt\"\n",
    "    slitNums = [3, 2, 1]\n",
    "    pointFolder = \"m_check_output/triple_1/\"\n",
    "    pointPrefix = \"pointing_\"\n",
    "    pointSuffix = \"/ds9_targ_regions.txt\"\n",
    "    pointNums = [7, 8, 13]\n",
    "    lossFolder = \"Slit-losses/HST/pathlosses_deep_R100/R100_v0/\"\n",
    "    lossPoints = [\"p01\", \"p02\", \"p03\"]\n",
    "    lossPrefix01 = \"pathlosses_correction_deep_hst_1x1_\"\n",
    "    lossPrefix02 = \"_idcat\"\n",
    "    lossExps = [\"exp00\", \"exp01\", \"exp02\"]\n",
    "    lossSuffix = \"_v0_point.txt\"\n",
    "\n",
    "# Filters\n",
    "try:\n",
    "    filterData\n",
    "except NameError:\n",
    "    filterDir, filterList, filterNames = GetFilter()\n",
    "    filterData = ImportFilter(filterDir, filterList, filterNames)\n",
    "\n",
    "# Redshift catalogue\n",
    "try:\n",
    "    redshiftFile\n",
    "except NameError:\n",
    "    redshiftFolder = GetDirStruct() + \"Redshifts/Deep_HST.csv\"\n",
    "    redshiftID = \"ID\"\n",
    "    redshiftZ = \"Assigned_redshift\"\n",
    "    redshiftFile = tbl.Table.read(redshiftFolder)\n",
    "\n",
    "# Spectra\n",
    "try:\n",
    "    specData\n",
    "    specTable\n",
    "except NameError:\n",
    "    specDir, specList, specNames = GetSpec()\n",
    "    specData = ImportSpec(specDir, specList, specNames)\n",
    "    specTable = LoopSpectra(specData, filterData, redshiftFile)\n",
    "    \n",
    "# Photometry\n",
    "try:\n",
    "    photTables\n",
    "except NameError:\n",
    "    photTables = ImportPhot()\n",
    "    \n",
    "# Astrometry\n",
    "try:\n",
    "    astroTables\n",
    "except NameError:\n",
    "    astroTables = ImportAstro()\n",
    "\n",
    "# Slitlosses\n",
    "try:\n",
    "    lossData\n",
    "except NameError:\n",
    "    lossDir, lossList = GrabSlitloss()\n",
    "    lossData = ImportSlitloss(lossDir, lossList, photTables)\n",
    "\n",
    "# Plots\n",
    "PlotSpec(specData, specList, specNames)\n",
    "\n",
    "# Slit-losses\n",
    "ratioTables, lossTables, diffTables = HandleSlitloss(lossData, photTables, astroTables, specTable)\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d6f00-227f-4326-a195-feac4e75c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffTables[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68296bb1-ef63-4c2b-ab86-de86455f66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.Jy.find_equivalent_units(equivalencies=u.spectral_density())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537b2ad-1f57-44c5-9bc5-057cedef5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.Table.read(\"/mnt/d/Astrometry/HST_Deep/for_emma_v2a_clean2/prism_trial_01_v2a_clean2/m_make_output/table3.txt\", format=\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ffffb-873b-4af0-bbc6-805970a445f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.Table.read(\"/mnt/d/Astrometry/HST_Deep/for_emma_v2a_clean2/prism_trial_01_v2a_clean2/m_check_output/triple_1/pointing_7/ds9_slit_regions.txt\", format=\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f26090-6a58-4a0f-b299-f93fdcc4dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "# plt.plot(Spectrum[\"Wavelength\"], Spectrum[\"Flux\"])\n",
    "# plt.plot(Filter[\"Wavelength\"], Filter[\"Throughput\"] * 10 **(-13))\n",
    "plt.plot(Filter_grid, Filter_conv * 10 ** (-13), color=\"green\")\n",
    "plt.plot(Filter_grid, Spectrum_flux, color=\"blue\")\n",
    "plt.plot(Filter_grid, Filter_conv * Spectrum_flux, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd018d-b194-4bad-97d6-34fe9161f83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
